{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc643b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/bin/python3.11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39aa8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: /usr/local/opt/python@3.11/bin/python3.11\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/opt/python@3.11/bin/python3.11 -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a0f2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b7623",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce63749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading uonlp_CulturaX__...\n",
      "Read uonlp_CulturaX__!\n",
      "Reading allenai_c4_en...\n",
      "Read allenai_c4_en!\n",
      "Reading dolma...\n",
      "Read dolma!\n",
      "Reading HuggingFaceFW_fineweb-edu_data__...\n",
      "Read HuggingFaceFW_fineweb-edu_data__!\n",
      "Reading tiiuae_falcon-refinedweb_data...\n",
      "Read tiiuae_falcon-refinedweb_data!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataframes_dict = {}\n",
    "for folder in Path('../consolidated_data_files').iterdir():\n",
    "    if folder.is_dir():\n",
    "        parquet_path = folder / 'consolidated.parquet'\n",
    "        if parquet_path.exists():\n",
    "            print(f\"Reading {folder.name}...\")\n",
    "            df = pd.read_parquet(parquet_path)\n",
    "            # Store in dictionary with name as key\n",
    "            dataframes_dict[folder.name] = df\n",
    "            print(f\"Read {folder.name}!\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efde091",
   "metadata": {},
   "source": [
    "# Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e78f5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uonlp_CulturaX__:\n",
      "  Rows: 109879658\n",
      "  Columns: 2\n",
      "  Memory usage: 1676.63 MB\n",
      "\n",
      "allenai_c4_en:\n",
      "  Rows: 15668873\n",
      "  Columns: 2\n",
      "  Memory usage: 239.09 MB\n",
      "\n",
      "dolma:\n",
      "  Rows: 331096\n",
      "  Columns: 2\n",
      "  Memory usage: 5.05 MB\n",
      "\n",
      "HuggingFaceFW_fineweb-edu_data__:\n",
      "  Rows: 12019813\n",
      "  Columns: 2\n",
      "  Memory usage: 183.41 MB\n",
      "\n",
      "tiiuae_falcon-refinedweb_data:\n",
      "  Rows: 33271341\n",
      "  Columns: 2\n",
      "  Memory usage: 507.68 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, df in dataframes_dict.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Rows: {df.shape[0]}\")\n",
    "    print(f\"  Columns: {df.shape[1]}\")\n",
    "    print(f\"  Memory usage: {df.memory_usage().sum() / 1024**2:.2f} MB\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4093022",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa926d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the URL counts per domain\n",
    "#url_counts = dataframes_dict['uonlp_CulturaX__']['count'].values\n",
    "url_counts = dataframes_dict['dolma']['count'].values\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create histogram with log-scale bins\n",
    "bins = np.logspace(np.log10(1), np.log10(url_counts.max()), 50)\n",
    "ax.hist(url_counts, bins=bins, alpha=0.7, color='#2563eb')\n",
    "\n",
    "# Set log scale for x-axis\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')  # Also using log scale for y-axis due to long tail\n",
    "\n",
    "# Customize labels and title\n",
    "ax.set_xlabel('URLs per Domain (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Number of Domains (log scale)', fontsize=12)\n",
    "ax.set_title('Distribution of URLs per Domain', fontsize=14, pad=20)\n",
    "\n",
    "# Customize grid and spines\n",
    "ax.grid(True, which='major', linestyle='-', alpha=0.2)\n",
    "ax.grid(True, which='minor', linestyle=':', alpha=0.2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add some statistics annotations\n",
    "stats_text = (\n",
    "    f'Total Domains: {len(url_counts):,}\\n'\n",
    "    f'Mean URLs/Domain: {url_counts.mean():.1f}\\n'\n",
    "    f'Median URLs/Domain: {np.median(url_counts):.1f}\\n'\n",
    "    f'Max URLs/Domain: {url_counts.max():,}'\n",
    ")\n",
    "ax.text(0.95, 0.95, stats_text,\n",
    "        transform=ax.transAxes,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4f0474",
   "metadata": {},
   "source": [
    "# Lorenz Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b0b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot Lorenz curve for each dataset with different colors\n",
    "colors = ['#2563eb', '#dc2626', '#16a34a', '#9333ea', '#ea580c', '#0891b2']\n",
    "for (name, df), color in zip(dataframes_dict.items(), colors):\n",
    "    # Sort domains by number of URLs\n",
    "    sorted_counts = np.sort(df['count'].values)\n",
    "    \n",
    "    # Calculate cumulative % of URLs\n",
    "    cumulative_urls = np.cumsum(sorted_counts) / sorted_counts.sum() * 100\n",
    "    \n",
    "    # Calculate cumulative % of domains\n",
    "    cumulative_domains = np.arange(1, len(sorted_counts) + 1) / len(sorted_counts) * 100\n",
    "    \n",
    "    # Plot the distribution\n",
    "    ax.plot(cumulative_domains, cumulative_urls, color=color, linewidth=2, label=name)\n",
    "    \n",
    "    # Print statistics for each dataset\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Top 1% domains hold {100 - cumulative_urls[int(0.99 * len(cumulative_urls))]:.1f}% of URLs\")\n",
    "    print(f\"  Top 10% domains hold {100 - cumulative_urls[int(0.90 * len(cumulative_urls))]:.1f}% of URLs\")\n",
    "    print(f\"  Median URLs per domain: {sorted_counts[len(sorted_counts)//2]:.1f}\")\n",
    "\n",
    "# Add diagonal line representing perfect equality\n",
    "ax.plot([0, 100], [0, 100], '--', color='gray', alpha=0.5, label='Perfect equality')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xlabel('Cumulative % of Domains', fontsize=12)\n",
    "ax.set_ylabel('Cumulative % of URLs', fontsize=12)\n",
    "ax.set_title('URL Distribution Across Domains by Dataset', fontsize=14, pad=20)\n",
    "\n",
    "# Customize grid and spines\n",
    "ax.grid(True, which='major', linestyle='-', alpha=0.2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add legend with smaller font and transparency\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, \n",
    "         framealpha=0.8, borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634722b6-0089-4b7f-9033-66ead7b6b8d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366bb05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define custom buckets and their labels\n",
    "bucket_edges = [1, 2, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "bucket_labels = ['1', '2-9', '10-99', '100-999', '1K-9.9K', '10K-99K', '100K+']\n",
    "\n",
    "# Calculate bar positions\n",
    "n_datasets = len(dataframes_dict)\n",
    "n_buckets = len(bucket_labels)\n",
    "bar_width = 0.15  # Width of each bar\n",
    "group_positions = np.arange(n_buckets)  # Center positions for each group\n",
    "\n",
    "colors = ['#2563eb', '#dc2626', '#16a34a', '#9333ea', '#ea580c', '#0891b2']\n",
    "for i, ((name, df), color) in enumerate(zip(dataframes_dict.items(), colors)):\n",
    "    bucket_counts = []\n",
    "    for j in range(len(bucket_edges)-1):\n",
    "        if j == len(bucket_edges)-2:  # Last bucket includes all higher values\n",
    "            count = ((df['count'] >= bucket_edges[j])).sum()\n",
    "        else:\n",
    "            count = ((df['count'] >= bucket_edges[j]) & \n",
    "                    (df['count'] < bucket_edges[j+1])).sum()\n",
    "        bucket_counts.append(count / len(df) * 100)  # Convert to percentage\n",
    "    \n",
    "    # Calculate bar positions\n",
    "    bar_positions = group_positions + (i - n_datasets/2 + 0.5) * bar_width\n",
    "    \n",
    "    # Plot bars\n",
    "    ax.bar(bar_positions, \n",
    "           bucket_counts,\n",
    "           width=bar_width,\n",
    "           color=color,\n",
    "           label=name)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Mean URLs per domain: {df['count'].mean():.1f}\")\n",
    "    print(f\"  Median URLs per domain: {df['count'].median():.1f}\")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xticks(group_positions)\n",
    "ax.set_xticklabels(bucket_labels, rotation=45)\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "ax.set_xlabel('URLs per Domain', fontsize=12)\n",
    "ax.set_ylabel('% of Domains', fontsize=12)\n",
    "ax.set_title('Distribution of URLs per Domain by Dataset', fontsize=14, pad=20)\n",
    "\n",
    "# Customize grid and spines\n",
    "ax.grid(True, which='major', linestyle='-', alpha=0.2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add legend with smaller font\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, \n",
    "         borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6c47f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc374bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "dolma_sample = dataframes_dict['dolma'].sample(10000)\n",
    "\n",
    "X = dolma_sample[['count']]\n",
    "\n",
    "# Dictionary to store silhouette scores\n",
    "silhouette_scores = {}\n",
    "\n",
    "# Test n_clusters from 3 to 10\n",
    "for n in range(3, 11):\n",
    "    clustering = AgglomerativeClustering(n_clusters=n)\n",
    "    labels = clustering.fit_predict(X)\n",
    "    dolma_sample[f\"cluster_{n}\"] = labels\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    if n > 1:  # Silhouette score requires at least 2 clusters\n",
    "        score = silhouette_score(X, labels)\n",
    "        silhouette_scores[n] = score\n",
    "\n",
    "# Print the DataFrame and silhouette scores\n",
    "print(dolma_sample.sample(10))\n",
    "print(\"Silhouette Scores:\", silhouette_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "dolma_sample_20k = dataframes_dict['dolma'].sample(20000)\n",
    "\n",
    "X = dolma_sample_20k[['count']]\n",
    "\n",
    "# Choose the optimal number of clusters (replace `optimal_n` with your value)\n",
    "optimal_n = 7\n",
    "\n",
    "# Run the clustering\n",
    "clustering = AgglomerativeClustering(n_clusters=optimal_n)\n",
    "dolma_sample_20k['cluster'] = clustering.fit_predict(X)\n",
    "\n",
    "# Calculate the range of values within each cluster\n",
    "cluster_ranges = (\n",
    "    dolma_sample_20k\n",
    "    .groupby('cluster')['count']\n",
    "    .agg(['min', 'max'])\n",
    "    .rename(columns={'min': 'min_count', 'max': 'max_count'})\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "print(\"\\nCluster Ranges:\")\n",
    "print(cluster_ranges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3672d-29d5-4a68-bddc-331d8a5b0317",
   "metadata": {},
   "source": [
    "# Common Crawl Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e61109d5-bcd9-4554-bfb1-0d3b22e1c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "bucket\n",
      "small         6416779\n",
      "one           5063140\n",
      "medium        3640376\n",
      "large          515031\n",
      "very_large      33547\n",
      "Name: count, dtype: int64\n",
      "small\n",
      "                                   domain  count bucket\n",
      "9076935           www.2dstageelectric.com    4.0  small\n",
      "13859404              www.revealuxion.com    6.0  small\n",
      "14564379                www.superwash.com    8.0  small\n",
      "315816    alarminstallationcapetown.co.za    5.0  small\n",
      "4116116                 irkarbeljaars.com    9.0  small\n",
      "\n",
      "one\n",
      "                             domain  count bucket\n",
      "12244980              www.kisfm.org    1.0    one\n",
      "2187248               dcampedup.com    1.0    one\n",
      "7608488                   sstong.kr    1.0    one\n",
      "5697117   nawbo.smallbusinesspr.com    1.0    one\n",
      "14789555  www.theleverageagency.com    1.0    one\n",
      "\n",
      "medium\n",
      "                           domain  count  bucket\n",
      "14514502  www.stripeystork.org.uk   32.0  medium\n",
      "12573864     www.lwvprinceton.org   34.0  medium\n",
      "12244920            www.kisco.com   50.0  medium\n",
      "1341798      bullseyestrategy.com   46.0  medium\n",
      "13879497   www.richsellshomes.com   44.0  medium\n",
      "\n",
      "large\n",
      "                              domain  count bucket\n",
      "4277651          jimhandsauction.com  197.0  large\n",
      "12910709  www.monstersandcritics.com  358.0  large\n",
      "12471135   www.lisaburridgehomes.com  145.0  large\n",
      "14422709           www.srectrade.com  232.0  large\n",
      "7355928                silverdice.us  229.0  large\n",
      "\n",
      "very_large\n",
      "                                domain   count      bucket\n",
      "10385826  www.cookinghawaiianstyle.com  1212.0  very_large\n",
      "11030984           www.exoticindia.com  1017.0  very_large\n",
      "2384283                docs.splunk.com  2869.0  very_large\n",
      "9344244        www.americamagazine.org  2119.0  very_large\n",
      "4966534                lta.reuters.com  2710.0  very_large\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html\n",
    "\n",
    "N_BUCKETS = 5\n",
    "N_SAMPLES_PER_BUCKET = 100\n",
    "\n",
    "# synthetic sample from parent data\n",
    "df = dataframes_dict['allenai_c4_en']\n",
    "\n",
    "# divide domains into buckets\n",
    "bins = [0, 1, 10, 100, 1000, df['count'].max()+1]#float('inf')]\n",
    "labels = ['one','small', 'medium', 'large', 'very_large']\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html\n",
    "df['bucket'] = pd.cut(df['count'], bins=bins, labels=labels)\n",
    "\n",
    "print(\"Distribution:\")\n",
    "print(df.bucket.value_counts())\n",
    "\n",
    "# print 5 sample domains from each bucket\n",
    "for bucket in df['bucket'].unique():\n",
    "    print(bucket)\n",
    "    bucket_domains = df[df['bucket'] == bucket].sample(5)\n",
    "    print(bucket_domains)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e80267a-4ef3-43c5-b4dd-1739dd5bedc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>count</th>\n",
       "      <th>bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6354079</th>\n",
       "      <td>pizza.dominos.com</td>\n",
       "      <td>11890.0</td>\n",
       "      <td>very_large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    domain    count      bucket\n",
       "6354079  pizza.dominos.com  11890.0  very_large"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.domain=='pizza.dominos.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761cfc7-6491-4424-ac5d-05c2f2913661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
