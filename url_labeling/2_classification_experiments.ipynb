{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6dafff-f875-46e7-984f-f0219c592393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "      <th>label_source</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>vicksburgpost.com</td>\n",
       "      <td>Local News</td>\n",
       "      <td>northeastern_domain_demo</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10739</th>\n",
       "      <td>southjerseylocalnews.com</td>\n",
       "      <td>Local News</td>\n",
       "      <td>northeastern_domain_demo</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>fws.gov</td>\n",
       "      <td>Legal &amp; Policy</td>\n",
       "      <td>data_provenance_init</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15211</th>\n",
       "      <td>ranker.com</td>\n",
       "      <td>News</td>\n",
       "      <td>data_provenance_init</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11218</th>\n",
       "      <td>thebellevuegazette.com</td>\n",
       "      <td>Local News</td>\n",
       "      <td>northeastern_domain_demo</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         domain           label              label_source  \\\n",
       "3203          vicksburgpost.com      Local News  northeastern_domain_demo   \n",
       "10739  southjerseylocalnews.com      Local News  northeastern_domain_demo   \n",
       "2061                    fws.gov  Legal & Policy      data_provenance_init   \n",
       "15211                ranker.com            News      data_provenance_init   \n",
       "11218    thebellevuegazette.com      Local News  northeastern_domain_demo   \n",
       "\n",
       "         set  \n",
       "3203    test  \n",
       "10739  train  \n",
       "2061   train  \n",
       "15211    val  \n",
       "11218  train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import hf_hub_download, list_repo_files\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "DATASETS = [\n",
    "            \"nhagar/c4_urls_en.noclean\"\n",
    "           ]\n",
    "\n",
    "# read in ground truth labels\n",
    "ground_truth_labels = pd.read_csv('../data/combined_domain_labels_16k_splits.csv')\n",
    "ground_truth_labels.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41551d69-f429-4c5c-941a-f5ad0395fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95 parquet files for nhagar/c4_urls_en.noclean\n",
      "Downloading all parquet files...\n",
      "Downloaded 95 files\n",
      "First file path: hf_cache/datasets--nhagar--c4_urls_en.noclean/snapshots/d0df683760e65bda672bf230c2673d7b2e07bfe2/batch_0/train-00000-of-00001.parquet\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:45<00:00, 45.88s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(DATASETS):\n",
    "    try:\n",
    "        # Get files list from repo\n",
    "        files = [f for f in list_repo_files(dataset, repo_type=\"dataset\") \n",
    "                if f.endswith('.parquet')]\n",
    "        if not files:\n",
    "            print(f\"No parquet files found for {dataset}, skipping\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Found {len(files)} parquet files for {dataset}\")\n",
    "        print(f\"Downloading all parquet files...\")\n",
    "        downloaded_files = []\n",
    "        \n",
    "        for file in files:\n",
    "            download_path = hf_hub_download(\n",
    "                repo_id=dataset,\n",
    "                filename=file,\n",
    "                repo_type=\"dataset\",\n",
    "                cache_dir=\"hf_cache\"\n",
    "            )\n",
    "            downloaded_files.append(download_path)\n",
    "        \n",
    "        print(f\"Downloaded {len(downloaded_files)} files\")\n",
    "        print(f\"First file path: {downloaded_files[0]}\")\n",
    "        print(\"Processing...\")\n",
    "        df = dd.read_parquet(downloaded_files).compute()\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {dataset}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857b0e43-e958-4a3b-a188-7d40e459b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter function to get URLs from domains with a ground truth label\n",
    "\n",
    "non_news_tlds = ('.edu', '.ru', '.mil', '.gov',\n",
    "                '.int','.museum','.travel','.shop',\n",
    "                 '.post','.jobs','.pro','.tel','.xyz')\n",
    "\n",
    "\n",
    "def filter_with_progress(df, domain_set, exclude_tlds=None, batch_size=100000):\n",
    "    start_time = time.time()\n",
    "    total_rows = len(df)\n",
    "    filtered_rows = []\n",
    "\n",
    "    for i in tqdm(range(0, total_rows, batch_size), desc=\"Filtering domains\"):\n",
    "        batch = df.iloc[i:min(i + batch_size, total_rows)]\n",
    "\n",
    "        # Filter by domains in the provided set\n",
    "        filtered_batch = batch[batch['domain'].isin(domain_set)]\n",
    "\n",
    "        # Include domains explicitly marked as non-news by their TLD\n",
    "        non_news_batch = batch[batch['domain'].str.endswith(tuple(non_news_tlds))]\n",
    "\n",
    "        # Combine both\n",
    "        combined_batch = pd.concat([filtered_batch, non_news_batch]).drop_duplicates()\n",
    "        filtered_rows.append(combined_batch)\n",
    "\n",
    "    return pd.concat(filtered_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2563ff0-05ec-469d-a9f7-bf438bd73aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_urls_per_domain(df, n=7, batch_size=100_000, random_state=42):\n",
    "    domain_count, results = {}, []\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Processing batches\"):\n",
    "        batch = df.iloc[i:i + batch_size]\n",
    "        eligible = {d for d, c in domain_count.items() if c < n}\n",
    "        filtered = batch if not eligible else batch[batch['domain'].isin(eligible)]\n",
    "\n",
    "        def sample_n(g):\n",
    "            domain = g.name if 'domain' not in g.columns else g['domain'].iloc[0]\n",
    "            s = g.sample(n=min(n, len(g)), random_state=random_state)\n",
    "            s['domain'] = domain\n",
    "            return s\n",
    "\n",
    "        sampled = filtered.groupby('domain', group_keys=False).apply(sample_n, include_groups=False)\n",
    "\n",
    "        try:\n",
    "            counts = sampled['domain'].value_counts()\n",
    "        except KeyError:\n",
    "            sampled = sampled.reset_index()  # recover if domain dropped\n",
    "            counts = sampled['domain'].value_counts()\n",
    "\n",
    "        for d, c in counts.items():\n",
    "            domain_count[d] = domain_count.get(d, 0) + c\n",
    "\n",
    "        results.append(sampled)\n",
    "\n",
    "        if domain_count and all(v >= n for v in domain_count.values()):\n",
    "            break\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8ebd25-da6a-4581-bee9-7fc9ad430c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering domains: 100%|████████████████████| 1894/1894 [06:04<00:00,  5.20it/s]\n"
     ]
    }
   ],
   "source": [
    "domain_set = set(ground_truth_labels['domain'])\n",
    "filtered_df = filter_with_progress(df, domain_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8153e3-ed30-49b0-857a-733c387bc662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20173318"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae119460-d6e4-4843-85a4-76be29f1a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|█████████████████████| 202/202 [00:36<00:00,  5.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82955"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = get_n_urls_per_domain(filtered_df)\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14afe52-c728-4431-91a7-a2eac87d9431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23400</th>\n",
       "      <td>http://abf-downloads.rosalinux.ru/jpisini_pers...</td>\n",
       "      <td>rosalinux.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73633</th>\n",
       "      <td>https://www.usagschweinfurt.jobs/jobs/healthca...</td>\n",
       "      <td>usagschweinfurt.jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>https://www.airuniversity.af.edu/AFNC/Articles/</td>\n",
       "      <td>af.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18408</th>\n",
       "      <td>https://www.nba.com/wizards/video/teams/wizard...</td>\n",
       "      <td>nba.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17798</th>\n",
       "      <td>http://sportsnetwork.msnbc.com/nba/boxscore.as...</td>\n",
       "      <td>msnbc.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81961</th>\n",
       "      <td>https://www.betteryou.xyz/2018/09/10/how-to-le...</td>\n",
       "      <td>betteryou.xyz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52898</th>\n",
       "      <td>http://domydom.ru/map36.html</td>\n",
       "      <td>domydom.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23662</th>\n",
       "      <td>https://posting.sacurrent.com/sanantonio/Tools...</td>\n",
       "      <td>sacurrent.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47311</th>\n",
       "      <td>https://www.consumer.ftc.gov/blog/2018/03/watc...</td>\n",
       "      <td>ftc.gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65054</th>\n",
       "      <td>https://www.rosbank.ru/en/press_service/news/y...</td>\n",
       "      <td>rosbank.ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url                domain\n",
       "23400  http://abf-downloads.rosalinux.ru/jpisini_pers...          rosalinux.ru\n",
       "73633  https://www.usagschweinfurt.jobs/jobs/healthca...  usagschweinfurt.jobs\n",
       "619      https://www.airuniversity.af.edu/AFNC/Articles/                af.edu\n",
       "18408  https://www.nba.com/wizards/video/teams/wizard...               nba.com\n",
       "17798  http://sportsnetwork.msnbc.com/nba/boxscore.as...             msnbc.com\n",
       "81961  https://www.betteryou.xyz/2018/09/10/how-to-le...         betteryou.xyz\n",
       "52898                       http://domydom.ru/map36.html            domydom.ru\n",
       "23662  https://posting.sacurrent.com/sanantonio/Tools...         sacurrent.com\n",
       "47311  https://www.consumer.ftc.gov/blog/2018/03/watc...               ftc.gov\n",
       "65054  https://www.rosbank.ru/en/press_service/news/y...            rosbank.ru"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2212fdae-9deb-4901-9474-8d12cd9685c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting domain news mapping...\n",
      "Domain news mapping completed in 0.13 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Starting domain news mapping...\")\n",
    "\n",
    "# Label 'is_news' based on presence of 'News' in 'label'\n",
    "ground_truth_labels['is_news'] = ground_truth_labels['label'].apply(lambda x: 1 if 'News' in x else 0)\n",
    "\n",
    "# Create mapping of domain to is_news\n",
    "domain_news_map = ground_truth_labels[['domain', 'is_news']].copy()\n",
    "\n",
    "# Merge with test_df\n",
    "test_df = test_df.merge(domain_news_map, on='domain', how='left')\n",
    "\n",
    "# Set is_news to 0 for known non-news TLDs\n",
    "test_df.loc[test_df['domain'].str.endswith(non_news_tlds), 'is_news'] = 0\n",
    "\n",
    "print(f\"Domain news mapping completed in {time.time() - start:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ceea2a7-c417-4e9a-b198-35cb0343e00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_news\n",
       "0.0    50092\n",
       "1.0    32863\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.is_news.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a91ae9-068a-48ab-8d09-0dfee7816d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82955"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07dbfdff-9864-4c28-bb0d-39a99c1c4b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      82955.0\n",
       "mean     76.298306\n",
       "std      44.470288\n",
       "min           16.0\n",
       "25%           50.0\n",
       "50%           68.0\n",
       "75%           92.0\n",
       "max         1896.0\n",
       "Name: url, dtype: Float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.url.str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fdac53-710d-4325-9574-86755198556c",
   "metadata": {},
   "source": [
    "# Helper Functions for the Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e6b484-e35a-46c0-9668-0ca671b21539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Custom transformer for manual feature extraction\n",
    "class URLFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        feature_list = []\n",
    "        for url in X:\n",
    "            parsed = urlparse(url)\n",
    "            domain = parsed.netloc\n",
    "            path = parsed.path\n",
    "            query = parsed.query\n",
    "            \n",
    "            features = {\n",
    "                # --- Basic structural features ---\n",
    "                'url_length': len(url),\n",
    "                'domain_length': len(domain),\n",
    "                'path_length': len(path),\n",
    "                'num_slashes': url.count('/'),\n",
    "                'num_dots': url.count('.'),\n",
    "                'num_equal': url.count('='),\n",
    "                'num_params': len(query.split('&')) if query else 0,\n",
    "                'query_length': len(query),\n",
    "                'has_query_string': int(bool(query)),\n",
    "                'has_fragment': int(bool(parsed.fragment)),\n",
    "                'fragment_length': len(parsed.fragment),\n",
    "                'has_port': int(bool(parsed.port)),\n",
    "            \n",
    "                # --- Character-based stats ---\n",
    "                'num_digits': sum(c.isdigit() for c in url),\n",
    "                'digit_ratio': sum(c.isdigit() for c in url) / len(url) if len(url) > 0 else 0,\n",
    "                'num_dashes': url.count('-'),\n",
    "                'dash_ratio': url.count('-') / len(url) if len(url) > 0 else 0,\n",
    "                'domain_dash_ratio': domain.count('-') / len(domain) if len(domain) > 0 else 0,\n",
    "                'path_dash_ratio': path.count('-') / len(path) if len(path) > 0 else 0,\n",
    "                'num_hyphens': url.count('-'),  # Duplicate of num_dashes, included for clarity\n",
    "                'num_underscores': url.count('_'),\n",
    "                'num_semicolons': url.count(';'),\n",
    "                'num_at_symbols': url.count('@'),\n",
    "                'num_percent': url.count('%'),\n",
    "                'uppercase_ratio': sum(1 for c in url if c.isupper()) / len(url) if len(url) > 0 else 0,\n",
    "                'non_alnum_path_ratio': sum(not c.isalnum() for c in path) / len(path) if len(path) > 0 else 0,\n",
    "            \n",
    "                # --- Domain and TLD ---\n",
    "                'tld_length': len(domain.split('.')[-1]) if '.' in domain else 0,\n",
    "                'subdomain_depth': domain.count('.') - 1,\n",
    "                'domain_digit_ratio': sum(c.isdigit() for c in domain) / len(domain) if len(domain) > 0 else 0,\n",
    "                'has_ip_address': int(bool(re.match(r'(\\d{1,3}\\.){3}\\d{1,3}', domain))),\n",
    "                'is_very_short_domain': int(len(domain) < 5),\n",
    "            \n",
    "                # --- Path and segment stats ---\n",
    "                'num_path_segments': len([p for p in path.split('/') if p]),\n",
    "                'path_to_url_ratio': len(path) / len(url) if len(url) > 0 else 0,\n",
    "                'domain_to_url_ratio': len(domain) / len(url) if len(url) > 0 else 0,\n",
    "                'avg_segment_length': sum(len(p) for p in path.split('/') if p) / len([p for p in path.split('/') if p]) if path.strip('/') else 0,\n",
    "                'max_segment_length': max([len(p) for p in path.split('/') if p], default=0),\n",
    "                'std_segment_length': np.std([len(p) for p in path.split('/') if p]) if path.strip('/') else 0,\n",
    "                'numeric_segment_ratio': sum(1 for p in path.split('/') if p.isdigit()) / len([p for p in path.split('/') if p]) if path.strip('/') else 0,\n",
    "                'mostly_numeric_path': int(sum(1 for c in path if c.isdigit()) / len(path) > 0.5 if len(path) > 0 else 0),\n",
    "                'has_long_segment': int(any(len(p) > 20 for p in path.split('/') if p)),\n",
    "                'has_repeated_chars': int(bool(re.search(r'(.)\\1{2,}', path))),\n",
    "                'starts_ends_with_slash': int(path.startswith('/') and path.endswith('/')),\n",
    "                'path_digit_ratio': sum(c.isdigit() for c in path) / len(path) if len(path) > 0 else 0,\n",
    "                'char_type_diversity': len(set([\n",
    "                    'digit' if c.isdigit() else 'alpha' if c.isalpha() else 'other'\n",
    "                    for c in path\n",
    "                ])),\n",
    "                'path_entropy': -sum(\n",
    "                    (path.count(c) / len(path)) * np.log2(path.count(c) / len(path))\n",
    "                    for c in set(path)\n",
    "                ) if len(path) > 0 else 0,\n",
    "                'first_segment_length': len(path.split('/')[1]) if len(path.split('/')) > 1 else 0,\n",
    "                'last_segment_all_digits': int(path.split('/')[-1].isdigit() if path.split('/') else 0),\n",
    "                'mixed_segment_ratio': sum(\n",
    "                    bool(re.search(r'[a-zA-Z]', p)) and bool(re.search(r'\\d', p))\n",
    "                    for p in path.split('/') if p\n",
    "                ) / len([p for p in path.split('/') if p]) if path.strip('/') else 0,\n",
    "                'num_internal_slashes': path[1:].count('/') if path.startswith('/') else path.count('/'),\n",
    "            \n",
    "                # --- Keyword-derived (optional if canonicalized) ---\n",
    "                'has_news_in_domain': int('news' in domain.lower()),\n",
    "                'has_news_in_path': int('news' in path.lower()),\n",
    "                'has_article_in_path': int('article' in path.lower()),\n",
    "                'has_content_in_path': int('content' in path.lower()),\n",
    "                'has_story_in_path': int('story' in path.lower()),\n",
    "                'has_blog_in_url': int('blog' in url.lower()),\n",
    "                'has_date_pattern': int(bool(re.search(r'/(19|20)\\d{2}[-/](0[1-9]|1[0-2])[-/](0[1-9]|[12][0-9]|3[01])/', url))),\n",
    "            }\n",
    "            feature_list.append(features)\n",
    "        return pd.DataFrame(feature_list).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8997a9-74f5-4302-a14b-18bb09262fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 1000\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import time\n",
    "\n",
    "def create_vectorizers():\n",
    "    return {\n",
    "        'Full Path (Word)': TfidfVectorizer(analyzer='word', ngram_range=(1, 5), max_features=N_FEATURES, token_pattern=r'[a-zA-Z0-9]+'),\n",
    "        'Full Path (Char)': TfidfVectorizer(analyzer='char', ngram_range=(2, 5), max_features=N_FEATURES),\n",
    "        'Full Path (Custom Token)': TfidfVectorizer(analyzer='word',tokenizer=lambda x: x.split('/'),ngram_range=(1, 3),max_features=500),\n",
    "        'Full Path (Hash)': HashingVectorizer(analyzer='char', ngram_range=(2, 5), n_features=N_FEATURES, alternate_sign=False),\n",
    "        'Path Only (Char)': TfidfVectorizer(analyzer='char', ngram_range=(2, 5), max_features=N_FEATURES),\n",
    "        'Path Only (Word)': TfidfVectorizer(analyzer='word', ngram_range=(1, 5), max_features=N_FEATURES, token_pattern=r'[a-zA-Z0-9]+'),\n",
    "        'Manual Features': URLFeatureExtractor()\n",
    "    }\n",
    "\n",
    "def prepare_features(train_df, test_df, vectorizers):\n",
    "    features = {}\n",
    "    for name, vec in vectorizers.items():\n",
    "        if 'Full Path' in name:\n",
    "            col = 'url'\n",
    "        elif 'Path Only' in name:\n",
    "            col = 'url'  # Use full URL but remove domain\n",
    "            train_df = train_df.copy()\n",
    "            test_df = test_df.copy()\n",
    "            train_df[col] = train_df['url'].apply(lambda x: urlparse(x).path)\n",
    "            test_df[col] = test_df['url'].apply(lambda x: urlparse(x).path)\n",
    "        elif 'Manual' in name:\n",
    "            col = 'url'\n",
    "        else:\n",
    "            continue  # For now\n",
    "\n",
    "        features[name] = {\n",
    "            'X_train': vec.fit_transform(train_df[col]),\n",
    "            'X_test': vec.transform(test_df[col])\n",
    "        }\n",
    "    return features\n",
    "\n",
    "def get_class_metric(report, label, metric):\n",
    "    for key in [label, str(label), float(label), str(float(label))]:\n",
    "        if key in report and metric in report[key]:\n",
    "            return report[key][metric]\n",
    "    return None\n",
    "\n",
    "def evaluate(name, X_train, X_test, y_train, y_test, model_cls):\n",
    "    if inspect.isclass(model_cls) or isinstance(model_cls, type):\n",
    "        sig = inspect.signature(model_cls)\n",
    "        if 'random_state' in sig.parameters:\n",
    "            model = Pipeline([('clf', model_cls(random_state=42))])\n",
    "        else:\n",
    "            model = Pipeline([('clf', model_cls())])\n",
    "    else:\n",
    "        # It's a lambda or factory function\n",
    "        model = Pipeline([('clf', model_cls())])\n",
    "    \n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    t0 = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    infer_time = time.time() - t0\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    print(f\"\\n{name}\\nTrain: {train_time:.2f}s | Inference: {infer_time:.2f}s\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    results = {\n",
    "        'Strategy': name,\n",
    "        'Train Time (s)': train_time,\n",
    "        'Inference Time (s)': infer_time,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1 (Class 0)': get_class_metric(report, 0, 'f1-score'),\n",
    "        'Precision (Class 0)': get_class_metric(report, 0, 'precision'),\n",
    "        'Recall (Class 0)': get_class_metric(report, 0, 'recall'),\n",
    "        'F1 (Class 1)': get_class_metric(report, 1, 'f1-score'),\n",
    "        'Precision (Class 1)': get_class_metric(report, 1, 'precision'),\n",
    "        'Recall (Class 1)': get_class_metric(report, 1, 'recall'),\n",
    "        'F2 (Class 0)': fbeta_score(y_test, y_pred, beta=2, pos_label=0),\n",
    "        'F2 (Class 1)': fbeta_score(y_test, y_pred, beta=2, pos_label=1),\n",
    "        'F1 (Weighted)': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'F2 (Weighted)': fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba280b-a321-47e9-b42f-611d8ccdeb10",
   "metadata": {},
   "source": [
    "# Actual Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8c47c0d-8c01-42dd-a94e-4a31b5a243f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Full Path (Word) + LogReg\n",
      "\n",
      "Full Path (Word) + LogReg\n",
      "Train: 0.27s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93     10089\n",
      "         1.0       0.87      0.93      0.90      6552\n",
      "\n",
      "    accuracy                           0.92     16641\n",
      "   macro avg       0.91      0.92      0.91     16641\n",
      "weighted avg       0.92      0.92      0.92     16641\n",
      "\n",
      "Training: Full Path (Word) + RandomForest\n",
      "\n",
      "Full Path (Word) + RandomForest\n",
      "Train: 40.05s | Inference: 0.33s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93     10089\n",
      "         1.0       0.86      0.94      0.90      6552\n",
      "\n",
      "    accuracy                           0.91     16641\n",
      "   macro avg       0.91      0.92      0.91     16641\n",
      "weighted avg       0.92      0.91      0.92     16641\n",
      "\n",
      "Training: Full Path (Word) + KNN (k=3)\n",
      "\n",
      "Full Path (Word) + KNN (k=3)\n",
      "Train: 0.01s | Inference: 34.72s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.89      0.87     10089\n",
      "         1.0       0.82      0.78      0.80      6552\n",
      "\n",
      "    accuracy                           0.85     16641\n",
      "   macro avg       0.84      0.83      0.84     16641\n",
      "weighted avg       0.85      0.85      0.85     16641\n",
      "\n",
      "Training: Full Path (Word) + KNN (k=1)\n",
      "\n",
      "Full Path (Word) + KNN (k=1)\n",
      "Train: 0.01s | Inference: 30.69s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.87      0.87     10089\n",
      "         1.0       0.80      0.78      0.79      6552\n",
      "\n",
      "    accuracy                           0.84     16641\n",
      "   macro avg       0.83      0.83      0.83     16641\n",
      "weighted avg       0.84      0.84      0.84     16641\n",
      "\n",
      "Training: Full Path (Word) + DecisionTree\n",
      "\n",
      "Full Path (Word) + DecisionTree\n",
      "Train: 7.52s | Inference: 0.01s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91     10089\n",
      "         1.0       0.86      0.87      0.86      6552\n",
      "\n",
      "    accuracy                           0.89     16641\n",
      "   macro avg       0.89      0.89      0.89     16641\n",
      "weighted avg       0.89      0.89      0.89     16641\n",
      "\n",
      "Training: Full Path (Word) + NaiveBayes\n",
      "\n",
      "Full Path (Word) + NaiveBayes\n",
      "Train: 0.02s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.92      0.91     10089\n",
      "         1.0       0.87      0.84      0.86      6552\n",
      "\n",
      "    accuracy                           0.89     16641\n",
      "   macro avg       0.89      0.88      0.88     16641\n",
      "weighted avg       0.89      0.89      0.89     16641\n",
      "\n",
      "Training: Full Path (Char) + LogReg\n",
      "\n",
      "Full Path (Char) + LogReg\n",
      "Train: 0.78s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.92      0.93     10089\n",
      "         1.0       0.88      0.92      0.90      6552\n",
      "\n",
      "    accuracy                           0.92     16641\n",
      "   macro avg       0.91      0.92      0.92     16641\n",
      "weighted avg       0.92      0.92      0.92     16641\n",
      "\n",
      "Training: Full Path (Char) + RandomForest\n",
      "\n",
      "Full Path (Char) + RandomForest\n",
      "Train: 150.76s | Inference: 0.36s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.89      0.93     10089\n",
      "         1.0       0.85      0.95      0.90      6552\n",
      "\n",
      "    accuracy                           0.91     16641\n",
      "   macro avg       0.91      0.92      0.91     16641\n",
      "weighted avg       0.92      0.91      0.91     16641\n",
      "\n",
      "Training: Full Path (Char) + KNN (k=3)\n",
      "\n",
      "Full Path (Char) + KNN (k=3)\n",
      "Train: 0.03s | Inference: 116.12s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91     10089\n",
      "         1.0       0.86      0.87      0.86      6552\n",
      "\n",
      "    accuracy                           0.89     16641\n",
      "   macro avg       0.89      0.89      0.89     16641\n",
      "weighted avg       0.89      0.89      0.89     16641\n",
      "\n",
      "Training: Full Path (Char) + KNN (k=1)\n",
      "\n",
      "Full Path (Char) + KNN (k=1)\n",
      "Train: 0.03s | Inference: 111.09s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90     10089\n",
      "         1.0       0.85      0.85      0.85      6552\n",
      "\n",
      "    accuracy                           0.88     16641\n",
      "   macro avg       0.88      0.88      0.88     16641\n",
      "weighted avg       0.88      0.88      0.88     16641\n",
      "\n",
      "Training: Full Path (Char) + DecisionTree\n",
      "\n",
      "Full Path (Char) + DecisionTree\n",
      "Train: 47.99s | Inference: 0.02s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.90      0.91     10089\n",
      "         1.0       0.85      0.87      0.86      6552\n",
      "\n",
      "    accuracy                           0.89     16641\n",
      "   macro avg       0.88      0.89      0.88     16641\n",
      "weighted avg       0.89      0.89      0.89     16641\n",
      "\n",
      "Training: Full Path (Char) + NaiveBayes\n",
      "\n",
      "Full Path (Char) + NaiveBayes\n",
      "Train: 0.04s | Inference: 0.01s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.89      0.90     10089\n",
      "         1.0       0.83      0.88      0.86      6552\n",
      "\n",
      "    accuracy                           0.88     16641\n",
      "   macro avg       0.88      0.88      0.88     16641\n",
      "weighted avg       0.89      0.88      0.88     16641\n",
      "\n",
      "Training: Full Path (Custom Token) + LogReg\n",
      "\n",
      "Full Path (Custom Token) + LogReg\n",
      "Train: 0.18s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.88      0.83     10089\n",
      "         1.0       0.77      0.61      0.68      6552\n",
      "\n",
      "    accuracy                           0.77     16641\n",
      "   macro avg       0.77      0.74      0.75     16641\n",
      "weighted avg       0.77      0.77      0.77     16641\n",
      "\n",
      "Training: Full Path (Custom Token) + RandomForest\n",
      "\n",
      "Full Path (Custom Token) + RandomForest\n",
      "Train: 21.96s | Inference: 0.22s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.90      0.83     10089\n",
      "         1.0       0.79      0.59      0.68      6552\n",
      "\n",
      "    accuracy                           0.78     16641\n",
      "   macro avg       0.78      0.74      0.75     16641\n",
      "weighted avg       0.78      0.78      0.77     16641\n",
      "\n",
      "Training: Full Path (Custom Token) + KNN (k=3)\n",
      "\n",
      "Full Path (Custom Token) + KNN (k=3)\n",
      "Train: 0.01s | Inference: 30.09s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.68      0.70     10089\n",
      "         1.0       0.55      0.60      0.58      6552\n",
      "\n",
      "    accuracy                           0.65     16641\n",
      "   macro avg       0.64      0.64      0.64     16641\n",
      "weighted avg       0.66      0.65      0.65     16641\n",
      "\n",
      "Training: Full Path (Custom Token) + KNN (k=1)\n",
      "\n",
      "Full Path (Custom Token) + KNN (k=1)\n",
      "Train: 0.01s | Inference: 26.33s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.67      0.71     10089\n",
      "         1.0       0.57      0.67      0.61      6552\n",
      "\n",
      "    accuracy                           0.67     16641\n",
      "   macro avg       0.66      0.67      0.66     16641\n",
      "weighted avg       0.68      0.67      0.67     16641\n",
      "\n",
      "Training: Full Path (Custom Token) + DecisionTree\n",
      "\n",
      "Full Path (Custom Token) + DecisionTree\n",
      "Train: 1.28s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.90      0.82     10089\n",
      "         1.0       0.78      0.57      0.66      6552\n",
      "\n",
      "    accuracy                           0.77     16641\n",
      "   macro avg       0.77      0.73      0.74     16641\n",
      "weighted avg       0.77      0.77      0.76     16641\n",
      "\n",
      "Training: Full Path (Custom Token) + NaiveBayes\n",
      "\n",
      "Full Path (Custom Token) + NaiveBayes\n",
      "Train: 0.02s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.89      0.83     10089\n",
      "         1.0       0.78      0.59      0.67      6552\n",
      "\n",
      "    accuracy                           0.77     16641\n",
      "   macro avg       0.77      0.74      0.75     16641\n",
      "weighted avg       0.77      0.77      0.77     16641\n",
      "\n",
      "Training: Full Path (Hash) + LogReg\n",
      "\n",
      "Full Path (Hash) + LogReg\n",
      "Train: 1.23s | Inference: 0.06s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92     10089\n",
      "         1.0       0.86      0.90      0.88      6552\n",
      "\n",
      "    accuracy                           0.90     16641\n",
      "   macro avg       0.89      0.90      0.90     16641\n",
      "weighted avg       0.90      0.90      0.90     16641\n",
      "\n",
      "Training: Full Path (Hash) + RandomForest\n",
      "\n",
      "Full Path (Hash) + RandomForest\n",
      "Train: 308.50s | Inference: 0.67s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.89      0.91     10089\n",
      "         1.0       0.84      0.89      0.86      6552\n",
      "\n",
      "    accuracy                           0.89     16641\n",
      "   macro avg       0.88      0.89      0.89     16641\n",
      "weighted avg       0.89      0.89      0.89     16641\n",
      "\n",
      "Training: Full Path (Hash) + KNN (k=3)\n",
      "\n",
      "Full Path (Hash) + KNN (k=3)\n",
      "Train: 0.10s | Inference: 209.88s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.82      0.87     10089\n",
      "         1.0       0.76      0.90      0.83      6552\n",
      "\n",
      "    accuracy                           0.85     16641\n",
      "   macro avg       0.85      0.86      0.85     16641\n",
      "weighted avg       0.86      0.85      0.85     16641\n",
      "\n",
      "Training: Full Path (Hash) + KNN (k=1)\n",
      "\n",
      "Full Path (Hash) + KNN (k=1)\n",
      "Train: 0.05s | Inference: 209.11s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87     10089\n",
      "         1.0       0.77      0.87      0.81      6552\n",
      "\n",
      "    accuracy                           0.84     16641\n",
      "   macro avg       0.84      0.85      0.84     16641\n",
      "weighted avg       0.85      0.84      0.85     16641\n",
      "\n",
      "Training: Full Path (Hash) + DecisionTree\n",
      "\n",
      "Full Path (Hash) + DecisionTree\n",
      "Train: 419.47s | Inference: 0.02s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88     10089\n",
      "         1.0       0.82      0.82      0.82      6552\n",
      "\n",
      "    accuracy                           0.86     16641\n",
      "   macro avg       0.85      0.85      0.85     16641\n",
      "weighted avg       0.86      0.86      0.86     16641\n",
      "\n",
      "Training: Full Path (Hash) + NaiveBayes\n",
      "\n",
      "Full Path (Hash) + NaiveBayes\n",
      "Train: 0.07s | Inference: 0.01s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.93      0.87     10089\n",
      "         1.0       0.86      0.67      0.76      6552\n",
      "\n",
      "    accuracy                           0.83     16641\n",
      "   macro avg       0.84      0.80      0.81     16641\n",
      "weighted avg       0.83      0.83      0.82     16641\n",
      "\n",
      "Training: Path Only (Char) + LogReg\n",
      "\n",
      "Path Only (Char) + LogReg\n",
      "Train: 0.25s | Inference: 0.01s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.84      0.82     10089\n",
      "         1.0       0.73      0.68      0.71      6552\n",
      "\n",
      "    accuracy                           0.78     16641\n",
      "   macro avg       0.77      0.76      0.76     16641\n",
      "weighted avg       0.78      0.78      0.78     16641\n",
      "\n",
      "Training: Path Only (Char) + RandomForest\n",
      "\n",
      "Path Only (Char) + RandomForest\n",
      "Train: 895.19s | Inference: 2.13s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.84     10089\n",
      "         1.0       0.79      0.69      0.73      6552\n",
      "\n",
      "    accuracy                           0.80     16641\n",
      "   macro avg       0.80      0.78      0.79     16641\n",
      "weighted avg       0.80      0.80      0.80     16641\n",
      "\n",
      "Training: Path Only (Char) + KNN (k=3)\n",
      "\n",
      "Path Only (Char) + KNN (k=3)\n",
      "Train: 0.09s | Inference: 1220.69s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.91      0.78     10089\n",
      "         1.0       0.71      0.36      0.48      6552\n",
      "\n",
      "    accuracy                           0.69     16641\n",
      "   macro avg       0.70      0.63      0.63     16641\n",
      "weighted avg       0.70      0.69      0.66     16641\n",
      "\n",
      "Training: Path Only (Char) + KNN (k=1)\n",
      "\n",
      "Path Only (Char) + KNN (k=1)\n",
      "Train: 0.04s | Inference: 1446.12s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.88      0.78     10089\n",
      "         1.0       0.70      0.44      0.54      6552\n",
      "\n",
      "    accuracy                           0.71     16641\n",
      "   macro avg       0.70      0.66      0.66     16641\n",
      "weighted avg       0.70      0.71      0.69     16641\n",
      "\n",
      "Training: Path Only (Char) + DecisionTree\n",
      "\n",
      "Path Only (Char) + DecisionTree\n",
      "Train: 597.84s | Inference: 0.01s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.78      0.77     10089\n",
      "         1.0       0.65      0.65      0.65      6552\n",
      "\n",
      "    accuracy                           0.72     16641\n",
      "   macro avg       0.71      0.71      0.71     16641\n",
      "weighted avg       0.72      0.72      0.72     16641\n",
      "\n",
      "Training: Path Only (Char) + NaiveBayes\n",
      "\n",
      "Path Only (Char) + NaiveBayes\n",
      "Train: 0.03s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.81      0.79     10089\n",
      "         1.0       0.69      0.65      0.67      6552\n",
      "\n",
      "    accuracy                           0.74     16641\n",
      "   macro avg       0.73      0.73      0.73     16641\n",
      "weighted avg       0.74      0.74      0.74     16641\n",
      "\n",
      "Training: Path Only (Word) + LogReg\n",
      "\n",
      "Path Only (Word) + LogReg\n",
      "Train: 0.12s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.85      0.83     10089\n",
      "         1.0       0.75      0.69      0.72      6552\n",
      "\n",
      "    accuracy                           0.79     16641\n",
      "   macro avg       0.78      0.77      0.78     16641\n",
      "weighted avg       0.79      0.79      0.79     16641\n",
      "\n",
      "Training: Path Only (Word) + RandomForest\n",
      "\n",
      "Path Only (Word) + RandomForest\n",
      "Train: 59.31s | Inference: 1.30s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.83      0.83     10089\n",
      "         1.0       0.74      0.73      0.73      6552\n",
      "\n",
      "    accuracy                           0.79     16641\n",
      "   macro avg       0.78      0.78      0.78     16641\n",
      "weighted avg       0.79      0.79      0.79     16641\n",
      "\n",
      "Training: Path Only (Word) + KNN (k=3)\n",
      "\n",
      "Path Only (Word) + KNN (k=3)\n",
      "Train: 0.01s | Inference: 19.23s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.69      0.72     10089\n",
      "         1.0       0.58      0.65      0.61      6552\n",
      "\n",
      "    accuracy                           0.68     16641\n",
      "   macro avg       0.67      0.67      0.67     16641\n",
      "weighted avg       0.68      0.68      0.68     16641\n",
      "\n",
      "Training: Path Only (Word) + KNN (k=1)\n",
      "\n",
      "Path Only (Word) + KNN (k=1)\n",
      "Train: 0.01s | Inference: 15.67s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.72     10089\n",
      "         1.0       0.57      0.65      0.61      6552\n",
      "\n",
      "    accuracy                           0.67     16641\n",
      "   macro avg       0.66      0.67      0.66     16641\n",
      "weighted avg       0.68      0.67      0.67     16641\n",
      "\n",
      "Training: Path Only (Word) + DecisionTree\n",
      "\n",
      "Path Only (Word) + DecisionTree\n",
      "Train: 4.48s | Inference: 0.01s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.82      0.80     10089\n",
      "         1.0       0.70      0.67      0.69      6552\n",
      "\n",
      "    accuracy                           0.76     16641\n",
      "   macro avg       0.75      0.74      0.74     16641\n",
      "weighted avg       0.76      0.76      0.76     16641\n",
      "\n",
      "Training: Path Only (Word) + NaiveBayes\n",
      "\n",
      "Path Only (Word) + NaiveBayes\n",
      "Train: 0.01s | Inference: 0.00s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.82     10089\n",
      "         1.0       0.74      0.69      0.71      6552\n",
      "\n",
      "    accuracy                           0.78     16641\n",
      "   macro avg       0.77      0.76      0.77     16641\n",
      "weighted avg       0.78      0.78      0.78     16641\n",
      "\n",
      "Training: Manual Features + LogReg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manual Features + LogReg\n",
      "Train: 0.97s | Inference: 0.02s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.87      0.80     10089\n",
      "         1.0       0.72      0.51      0.60      6552\n",
      "\n",
      "    accuracy                           0.73     16641\n",
      "   macro avg       0.73      0.69      0.70     16641\n",
      "weighted avg       0.73      0.73      0.72     16641\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Manual Features + RandomForest\n",
      "\n",
      "Manual Features + RandomForest\n",
      "Train: 9.59s | Inference: 0.31s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.83      0.82     10089\n",
      "         1.0       0.73      0.68      0.70      6552\n",
      "\n",
      "    accuracy                           0.77     16641\n",
      "   macro avg       0.76      0.76      0.76     16641\n",
      "weighted avg       0.77      0.77      0.77     16641\n",
      "\n",
      "Training: Manual Features + KNN (k=3)\n",
      "\n",
      "Manual Features + KNN (k=3)\n",
      "Train: 0.02s | Inference: 1.90s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.77      0.78     10089\n",
      "         1.0       0.66      0.67      0.66      6552\n",
      "\n",
      "    accuracy                           0.73     16641\n",
      "   macro avg       0.72      0.72      0.72     16641\n",
      "weighted avg       0.73      0.73      0.73     16641\n",
      "\n",
      "Training: Manual Features + KNN (k=1)\n",
      "\n",
      "Manual Features + KNN (k=1)\n",
      "Train: 0.05s | Inference: 1.77s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.75      0.76     10089\n",
      "         1.0       0.63      0.65      0.64      6552\n",
      "\n",
      "    accuracy                           0.71     16641\n",
      "   macro avg       0.70      0.70      0.70     16641\n",
      "weighted avg       0.71      0.71      0.71     16641\n",
      "\n",
      "Training: Manual Features + DecisionTree\n",
      "\n",
      "Manual Features + DecisionTree\n",
      "Train: 0.77s | Inference: 0.01s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.77      0.77     10089\n",
      "         1.0       0.65      0.64      0.65      6552\n",
      "\n",
      "    accuracy                           0.72     16641\n",
      "   macro avg       0.71      0.71      0.71     16641\n",
      "weighted avg       0.72      0.72      0.72     16641\n",
      "\n",
      "Training: Manual Features + NaiveBayes\n",
      "Error fitting model 'NaiveBayes': Negative values in data passed to MultinomialNB (input X)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "domain_df = test_df.groupby('domain')['is_news'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "train_domains, test_domains = train_test_split(\n",
    "    domain_df['domain'], \n",
    "    test_size=0.2, \n",
    "    stratify=domain_df['is_news'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = test_df[test_df['domain'].isin(train_domains)]\n",
    "test_df = test_df[test_df['domain'].isin(test_domains)]\n",
    "\n",
    "X_train = train_df[['url']]\n",
    "y_train = train_df['is_news']\n",
    "X_test = test_df[['url']]\n",
    "y_test = test_df['is_news']\n",
    "\n",
    "\n",
    "# Create vectorizers\n",
    "vecs = create_vectorizers()\n",
    "\n",
    "# Prepare features using vectorizers\n",
    "features = prepare_features(X_train, X_test, vecs)\n",
    "\n",
    "# Prepare combined features separately\n",
    "combined_features = prepare_features(X_train, X_test, {'Combined': None})\n",
    "features.update(combined_features)\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    ('LogReg', LogisticRegression),\n",
    "    ('RandomForest', RandomForestClassifier),\n",
    "    ('KNN (k=3)', lambda: KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('KNN (k=1)', lambda: KNeighborsClassifier(n_neighbors=1)),\n",
    "    ('DecisionTree', DecisionTreeClassifier),\n",
    "    #('MLP', lambda: MLPClassifier(hidden_layer_sizes=(64,), max_iter=200)),\n",
    "    ('NaiveBayes', lambda: MultinomialNB())\n",
    "]\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "# Evaluate and save models\n",
    "results = []\n",
    "for strat, feat in features.items():\n",
    "    for name, cls in models:\n",
    "        model_label = f\"{strat} + {name}\"\n",
    "        print(f\"Training: {model_label}\")\n",
    "        try:\n",
    "            result = evaluate(model_label, feat['X_train'], feat['X_test'], y_train, y_test, cls)    \n",
    "            model = cls() if not callable(cls) else cls()        \n",
    "            model.fit(feat['X_train'], y_train)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting model '{name}': {e}\")\n",
    "        model_filename = f\"saved_models/{strat}_{name.replace(' ', '_')}.joblib\"\n",
    "        joblib.dump(model, model_filename)\n",
    "\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f97d7cc-c1f4-4452-b2f3-9f9cc6367ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 (Class 0)</th>\n",
       "      <th>Precision (Class 0)</th>\n",
       "      <th>Recall (Class 0)</th>\n",
       "      <th>F1 (Class 1)</th>\n",
       "      <th>Precision (Class 1)</th>\n",
       "      <th>Recall (Class 1)</th>\n",
       "      <th>F2 (Class 0)</th>\n",
       "      <th>F2 (Class 1)</th>\n",
       "      <th>F1 (Weighted)</th>\n",
       "      <th>F2 (Weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Full Path (Char) + LogReg</td>\n",
       "      <td>0.783373</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.919176</td>\n",
       "      <td>0.932156</td>\n",
       "      <td>0.949055</td>\n",
       "      <td>0.915849</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.877046</td>\n",
       "      <td>0.924298</td>\n",
       "      <td>0.922303</td>\n",
       "      <td>0.914444</td>\n",
       "      <td>0.919516</td>\n",
       "      <td>0.919209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full Path (Word) + LogReg</td>\n",
       "      <td>0.273773</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.917673</td>\n",
       "      <td>0.930457</td>\n",
       "      <td>0.953595</td>\n",
       "      <td>0.908415</td>\n",
       "      <td>0.899131</td>\n",
       "      <td>0.868563</td>\n",
       "      <td>0.931929</td>\n",
       "      <td>0.917105</td>\n",
       "      <td>0.918527</td>\n",
       "      <td>0.918123</td>\n",
       "      <td>0.917665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Path (Word) + RandomForest</td>\n",
       "      <td>40.046579</td>\n",
       "      <td>0.334814</td>\n",
       "      <td>0.914488</td>\n",
       "      <td>0.927357</td>\n",
       "      <td>0.956105</td>\n",
       "      <td>0.900287</td>\n",
       "      <td>0.896078</td>\n",
       "      <td>0.859123</td>\n",
       "      <td>0.936355</td>\n",
       "      <td>0.910923</td>\n",
       "      <td>0.919818</td>\n",
       "      <td>0.915042</td>\n",
       "      <td>0.914425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Full Path (Char) + RandomForest</td>\n",
       "      <td>150.761759</td>\n",
       "      <td>0.357640</td>\n",
       "      <td>0.913767</td>\n",
       "      <td>0.926202</td>\n",
       "      <td>0.962484</td>\n",
       "      <td>0.892556</td>\n",
       "      <td>0.896293</td>\n",
       "      <td>0.851201</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.905717</td>\n",
       "      <td>0.925716</td>\n",
       "      <td>0.914426</td>\n",
       "      <td>0.913591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Full Path (Hash) + LogReg</td>\n",
       "      <td>1.230849</td>\n",
       "      <td>0.059881</td>\n",
       "      <td>0.900367</td>\n",
       "      <td>0.916650</td>\n",
       "      <td>0.930021</td>\n",
       "      <td>0.903657</td>\n",
       "      <td>0.876176</td>\n",
       "      <td>0.857853</td>\n",
       "      <td>0.895299</td>\n",
       "      <td>0.908810</td>\n",
       "      <td>0.887551</td>\n",
       "      <td>0.900714</td>\n",
       "      <td>0.900440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Path (Word) + DecisionTree</td>\n",
       "      <td>7.515523</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.891833</td>\n",
       "      <td>0.910215</td>\n",
       "      <td>0.916156</td>\n",
       "      <td>0.904351</td>\n",
       "      <td>0.863987</td>\n",
       "      <td>0.855582</td>\n",
       "      <td>0.872558</td>\n",
       "      <td>0.906688</td>\n",
       "      <td>0.869109</td>\n",
       "      <td>0.892014</td>\n",
       "      <td>0.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Full Path (Char) + KNN (k=3)</td>\n",
       "      <td>0.028875</td>\n",
       "      <td>116.119892</td>\n",
       "      <td>0.891773</td>\n",
       "      <td>0.910429</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.907226</td>\n",
       "      <td>0.863302</td>\n",
       "      <td>0.858674</td>\n",
       "      <td>0.867979</td>\n",
       "      <td>0.908504</td>\n",
       "      <td>0.866102</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>0.891810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Full Path (Word) + NaiveBayes</td>\n",
       "      <td>0.020721</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.890031</td>\n",
       "      <td>0.910373</td>\n",
       "      <td>0.899797</td>\n",
       "      <td>0.921201</td>\n",
       "      <td>0.857743</td>\n",
       "      <td>0.874049</td>\n",
       "      <td>0.842033</td>\n",
       "      <td>0.916839</td>\n",
       "      <td>0.848247</td>\n",
       "      <td>0.889651</td>\n",
       "      <td>0.889833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Full Path (Hash) + RandomForest</td>\n",
       "      <td>308.501812</td>\n",
       "      <td>0.665472</td>\n",
       "      <td>0.889189</td>\n",
       "      <td>0.906661</td>\n",
       "      <td>0.926451</td>\n",
       "      <td>0.887699</td>\n",
       "      <td>0.863670</td>\n",
       "      <td>0.837539</td>\n",
       "      <td>0.891484</td>\n",
       "      <td>0.895188</td>\n",
       "      <td>0.880146</td>\n",
       "      <td>0.889734</td>\n",
       "      <td>0.889266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Full Path (Char) + DecisionTree</td>\n",
       "      <td>47.994331</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>0.888769</td>\n",
       "      <td>0.907704</td>\n",
       "      <td>0.913305</td>\n",
       "      <td>0.902171</td>\n",
       "      <td>0.860059</td>\n",
       "      <td>0.852135</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.904376</td>\n",
       "      <td>0.864885</td>\n",
       "      <td>0.888945</td>\n",
       "      <td>0.888827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Full Path (Char) + NaiveBayes</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.883300</td>\n",
       "      <td>0.902048</td>\n",
       "      <td>0.918353</td>\n",
       "      <td>0.886312</td>\n",
       "      <td>0.855678</td>\n",
       "      <td>0.833864</td>\n",
       "      <td>0.878663</td>\n",
       "      <td>0.892540</td>\n",
       "      <td>0.869322</td>\n",
       "      <td>0.883791</td>\n",
       "      <td>0.883399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Full Path (Char) + KNN (k=1)</td>\n",
       "      <td>0.033765</td>\n",
       "      <td>111.089114</td>\n",
       "      <td>0.881197</td>\n",
       "      <td>0.901959</td>\n",
       "      <td>0.902541</td>\n",
       "      <td>0.901378</td>\n",
       "      <td>0.849280</td>\n",
       "      <td>0.848439</td>\n",
       "      <td>0.850122</td>\n",
       "      <td>0.901610</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.881218</td>\n",
       "      <td>0.881205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Full Path (Hash) + DecisionTree</td>\n",
       "      <td>419.467187</td>\n",
       "      <td>0.024050</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.883269</td>\n",
       "      <td>0.883795</td>\n",
       "      <td>0.882744</td>\n",
       "      <td>0.820525</td>\n",
       "      <td>0.819775</td>\n",
       "      <td>0.821276</td>\n",
       "      <td>0.882954</td>\n",
       "      <td>0.820975</td>\n",
       "      <td>0.858565</td>\n",
       "      <td>0.858551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Full Path (Hash) + KNN (k=3)</td>\n",
       "      <td>0.098532</td>\n",
       "      <td>209.884235</td>\n",
       "      <td>0.851511</td>\n",
       "      <td>0.870146</td>\n",
       "      <td>0.926063</td>\n",
       "      <td>0.820597</td>\n",
       "      <td>0.826633</td>\n",
       "      <td>0.764966</td>\n",
       "      <td>0.899115</td>\n",
       "      <td>0.839723</td>\n",
       "      <td>0.868648</td>\n",
       "      <td>0.853014</td>\n",
       "      <td>0.851112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Path (Word) + KNN (k=3)</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>34.716234</td>\n",
       "      <td>0.845803</td>\n",
       "      <td>0.874634</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.887204</td>\n",
       "      <td>0.799750</td>\n",
       "      <td>0.818269</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.882133</td>\n",
       "      <td>0.789036</td>\n",
       "      <td>0.845150</td>\n",
       "      <td>0.845478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Full Path (Hash) + KNN (k=1)</td>\n",
       "      <td>0.053817</td>\n",
       "      <td>209.112356</td>\n",
       "      <td>0.843699</td>\n",
       "      <td>0.865268</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.827832</td>\n",
       "      <td>0.813909</td>\n",
       "      <td>0.766061</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.842411</td>\n",
       "      <td>0.845598</td>\n",
       "      <td>0.845046</td>\n",
       "      <td>0.843666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full Path (Word) + KNN (k=1)</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>30.688173</td>\n",
       "      <td>0.838291</td>\n",
       "      <td>0.867536</td>\n",
       "      <td>0.861725</td>\n",
       "      <td>0.873427</td>\n",
       "      <td>0.792473</td>\n",
       "      <td>0.800935</td>\n",
       "      <td>0.784188</td>\n",
       "      <td>0.871061</td>\n",
       "      <td>0.787481</td>\n",
       "      <td>0.837982</td>\n",
       "      <td>0.838153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Full Path (Hash) + NaiveBayes</td>\n",
       "      <td>0.071264</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>0.867353</td>\n",
       "      <td>0.814573</td>\n",
       "      <td>0.927446</td>\n",
       "      <td>0.755510</td>\n",
       "      <td>0.857974</td>\n",
       "      <td>0.674908</td>\n",
       "      <td>0.902436</td>\n",
       "      <td>0.704993</td>\n",
       "      <td>0.823317</td>\n",
       "      <td>0.824698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Path Only (Char) + RandomForest</td>\n",
       "      <td>895.194725</td>\n",
       "      <td>2.131135</td>\n",
       "      <td>0.802416</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>0.811544</td>\n",
       "      <td>0.877986</td>\n",
       "      <td>0.732204</td>\n",
       "      <td>0.785016</td>\n",
       "      <td>0.686050</td>\n",
       "      <td>0.863841</td>\n",
       "      <td>0.703795</td>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.800827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Path Only (Word) + LogReg</td>\n",
       "      <td>0.118259</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.790758</td>\n",
       "      <td>0.831787</td>\n",
       "      <td>0.811328</td>\n",
       "      <td>0.853306</td>\n",
       "      <td>0.723255</td>\n",
       "      <td>0.754561</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.844566</td>\n",
       "      <td>0.705689</td>\n",
       "      <td>0.789056</td>\n",
       "      <td>0.789886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Path Only (Word) + RandomForest</td>\n",
       "      <td>59.314191</td>\n",
       "      <td>1.295936</td>\n",
       "      <td>0.789616</td>\n",
       "      <td>0.827034</td>\n",
       "      <td>0.824468</td>\n",
       "      <td>0.829616</td>\n",
       "      <td>0.731539</td>\n",
       "      <td>0.735090</td>\n",
       "      <td>0.728022</td>\n",
       "      <td>0.828582</td>\n",
       "      <td>0.729425</td>\n",
       "      <td>0.789435</td>\n",
       "      <td>0.789541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Path Only (Word) + NaiveBayes</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.780302</td>\n",
       "      <td>0.822714</td>\n",
       "      <td>0.805374</td>\n",
       "      <td>0.840817</td>\n",
       "      <td>0.711216</td>\n",
       "      <td>0.737066</td>\n",
       "      <td>0.687118</td>\n",
       "      <td>0.833481</td>\n",
       "      <td>0.696559</td>\n",
       "      <td>0.778814</td>\n",
       "      <td>0.779571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Full Path (Custom Token) + RandomForest</td>\n",
       "      <td>21.956469</td>\n",
       "      <td>0.224109</td>\n",
       "      <td>0.777898</td>\n",
       "      <td>0.830924</td>\n",
       "      <td>0.771557</td>\n",
       "      <td>0.900188</td>\n",
       "      <td>0.676414</td>\n",
       "      <td>0.793224</td>\n",
       "      <td>0.589591</td>\n",
       "      <td>0.871142</td>\n",
       "      <td>0.621501</td>\n",
       "      <td>0.770089</td>\n",
       "      <td>0.772851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Path Only (Char) + LogReg</td>\n",
       "      <td>0.252705</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>0.776997</td>\n",
       "      <td>0.820299</td>\n",
       "      <td>0.801931</td>\n",
       "      <td>0.839528</td>\n",
       "      <td>0.706199</td>\n",
       "      <td>0.733673</td>\n",
       "      <td>0.680708</td>\n",
       "      <td>0.831729</td>\n",
       "      <td>0.690680</td>\n",
       "      <td>0.775375</td>\n",
       "      <td>0.776195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Full Path (Custom Token) + LogReg</td>\n",
       "      <td>0.175038</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.773211</td>\n",
       "      <td>0.825002</td>\n",
       "      <td>0.775115</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.677876</td>\n",
       "      <td>0.768978</td>\n",
       "      <td>0.606074</td>\n",
       "      <td>0.858141</td>\n",
       "      <td>0.632889</td>\n",
       "      <td>0.767075</td>\n",
       "      <td>0.769453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Full Path (Custom Token) + NaiveBayes</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.772730</td>\n",
       "      <td>0.826386</td>\n",
       "      <td>0.769645</td>\n",
       "      <td>0.892160</td>\n",
       "      <td>0.671073</td>\n",
       "      <td>0.780024</td>\n",
       "      <td>0.588828</td>\n",
       "      <td>0.864633</td>\n",
       "      <td>0.619182</td>\n",
       "      <td>0.765235</td>\n",
       "      <td>0.767992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Manual Features + RandomForest</td>\n",
       "      <td>9.585214</td>\n",
       "      <td>0.308872</td>\n",
       "      <td>0.772129</td>\n",
       "      <td>0.816119</td>\n",
       "      <td>0.798918</td>\n",
       "      <td>0.834077</td>\n",
       "      <td>0.700474</td>\n",
       "      <td>0.725933</td>\n",
       "      <td>0.676740</td>\n",
       "      <td>0.826800</td>\n",
       "      <td>0.686038</td>\n",
       "      <td>0.770586</td>\n",
       "      <td>0.771378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Full Path (Custom Token) + DecisionTree</td>\n",
       "      <td>1.281159</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.824294</td>\n",
       "      <td>0.761337</td>\n",
       "      <td>0.898602</td>\n",
       "      <td>0.657510</td>\n",
       "      <td>0.783858</td>\n",
       "      <td>0.566239</td>\n",
       "      <td>0.867327</td>\n",
       "      <td>0.599528</td>\n",
       "      <td>0.758627</td>\n",
       "      <td>0.761888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Path Only (Word) + DecisionTree</td>\n",
       "      <td>4.476643</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.758488</td>\n",
       "      <td>0.804056</td>\n",
       "      <td>0.791211</td>\n",
       "      <td>0.817326</td>\n",
       "      <td>0.685303</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.667888</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.674746</td>\n",
       "      <td>0.757300</td>\n",
       "      <td>0.757939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Path Only (Char) + NaiveBayes</td>\n",
       "      <td>0.031398</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.744487</td>\n",
       "      <td>0.793171</td>\n",
       "      <td>0.778775</td>\n",
       "      <td>0.808108</td>\n",
       "      <td>0.665828</td>\n",
       "      <td>0.686325</td>\n",
       "      <td>0.646520</td>\n",
       "      <td>0.802066</td>\n",
       "      <td>0.654107</td>\n",
       "      <td>0.743033</td>\n",
       "      <td>0.743811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Manual Features + KNN (k=3)</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>1.901771</td>\n",
       "      <td>0.731567</td>\n",
       "      <td>0.777085</td>\n",
       "      <td>0.782513</td>\n",
       "      <td>0.771732</td>\n",
       "      <td>0.662690</td>\n",
       "      <td>0.655806</td>\n",
       "      <td>0.669719</td>\n",
       "      <td>0.773864</td>\n",
       "      <td>0.666890</td>\n",
       "      <td>0.732044</td>\n",
       "      <td>0.731745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Manual Features + LogReg</td>\n",
       "      <td>0.968650</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.730425</td>\n",
       "      <td>0.797160</td>\n",
       "      <td>0.732934</td>\n",
       "      <td>0.873724</td>\n",
       "      <td>0.598245</td>\n",
       "      <td>0.723884</td>\n",
       "      <td>0.509768</td>\n",
       "      <td>0.841399</td>\n",
       "      <td>0.541821</td>\n",
       "      <td>0.718842</td>\n",
       "      <td>0.723447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Path Only (Char) + DecisionTree</td>\n",
       "      <td>597.837565</td>\n",
       "      <td>0.008841</td>\n",
       "      <td>0.724956</td>\n",
       "      <td>0.773741</td>\n",
       "      <td>0.771795</td>\n",
       "      <td>0.775696</td>\n",
       "      <td>0.649353</td>\n",
       "      <td>0.651900</td>\n",
       "      <td>0.646825</td>\n",
       "      <td>0.774913</td>\n",
       "      <td>0.647834</td>\n",
       "      <td>0.724766</td>\n",
       "      <td>0.724879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Manual Features + DecisionTree</td>\n",
       "      <td>0.770453</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.722132</td>\n",
       "      <td>0.771202</td>\n",
       "      <td>0.769983</td>\n",
       "      <td>0.772425</td>\n",
       "      <td>0.646267</td>\n",
       "      <td>0.647853</td>\n",
       "      <td>0.644689</td>\n",
       "      <td>0.771936</td>\n",
       "      <td>0.645319</td>\n",
       "      <td>0.722012</td>\n",
       "      <td>0.722083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Manual Features + DecisionTree</td>\n",
       "      <td>0.770453</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.722132</td>\n",
       "      <td>0.771202</td>\n",
       "      <td>0.769983</td>\n",
       "      <td>0.772425</td>\n",
       "      <td>0.646267</td>\n",
       "      <td>0.647853</td>\n",
       "      <td>0.644689</td>\n",
       "      <td>0.771936</td>\n",
       "      <td>0.645319</td>\n",
       "      <td>0.722012</td>\n",
       "      <td>0.722083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Manual Features + KNN (k=1)</td>\n",
       "      <td>0.045878</td>\n",
       "      <td>1.765950</td>\n",
       "      <td>0.708611</td>\n",
       "      <td>0.756930</td>\n",
       "      <td>0.765720</td>\n",
       "      <td>0.748340</td>\n",
       "      <td>0.636316</td>\n",
       "      <td>0.625571</td>\n",
       "      <td>0.647436</td>\n",
       "      <td>0.751752</td>\n",
       "      <td>0.642942</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.708911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Path Only (Char) + KNN (k=1)</td>\n",
       "      <td>0.043965</td>\n",
       "      <td>1446.119750</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.783538</td>\n",
       "      <td>0.706538</td>\n",
       "      <td>0.879374</td>\n",
       "      <td>0.539112</td>\n",
       "      <td>0.702008</td>\n",
       "      <td>0.437576</td>\n",
       "      <td>0.838357</td>\n",
       "      <td>0.473227</td>\n",
       "      <td>0.687301</td>\n",
       "      <td>0.694596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Path Only (Char) + KNN (k=3)</td>\n",
       "      <td>0.094505</td>\n",
       "      <td>1220.690966</td>\n",
       "      <td>0.691605</td>\n",
       "      <td>0.780721</td>\n",
       "      <td>0.686143</td>\n",
       "      <td>0.905541</td>\n",
       "      <td>0.480462</td>\n",
       "      <td>0.713470</td>\n",
       "      <td>0.362179</td>\n",
       "      <td>0.851111</td>\n",
       "      <td>0.401740</td>\n",
       "      <td>0.662501</td>\n",
       "      <td>0.674182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Path Only (Word) + KNN (k=3)</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>19.228129</td>\n",
       "      <td>0.676101</td>\n",
       "      <td>0.721476</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>0.691942</td>\n",
       "      <td>0.613065</td>\n",
       "      <td>0.578748</td>\n",
       "      <td>0.651709</td>\n",
       "      <td>0.703460</td>\n",
       "      <td>0.635682</td>\n",
       "      <td>0.678792</td>\n",
       "      <td>0.676774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Full Path (Custom Token) + KNN (k=1)</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>26.331409</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>0.712181</td>\n",
       "      <td>0.756068</td>\n",
       "      <td>0.673109</td>\n",
       "      <td>0.613750</td>\n",
       "      <td>0.569395</td>\n",
       "      <td>0.665598</td>\n",
       "      <td>0.688212</td>\n",
       "      <td>0.643842</td>\n",
       "      <td>0.673426</td>\n",
       "      <td>0.670742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Path Only (Word) + KNN (k=1)</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>15.673093</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>0.715086</td>\n",
       "      <td>0.750190</td>\n",
       "      <td>0.683120</td>\n",
       "      <td>0.607882</td>\n",
       "      <td>0.571103</td>\n",
       "      <td>0.649725</td>\n",
       "      <td>0.695557</td>\n",
       "      <td>0.632315</td>\n",
       "      <td>0.672877</td>\n",
       "      <td>0.670657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Full Path (Custom Token) + KNN (k=3)</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>30.086631</td>\n",
       "      <td>0.650382</td>\n",
       "      <td>0.702860</td>\n",
       "      <td>0.725003</td>\n",
       "      <td>0.682030</td>\n",
       "      <td>0.575390</td>\n",
       "      <td>0.551329</td>\n",
       "      <td>0.601648</td>\n",
       "      <td>0.690212</td>\n",
       "      <td>0.590863</td>\n",
       "      <td>0.652672</td>\n",
       "      <td>0.651096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Strategy  Train Time (s)  \\\n",
       "6                 Full Path (Char) + LogReg        0.783373   \n",
       "0                 Full Path (Word) + LogReg        0.273773   \n",
       "1           Full Path (Word) + RandomForest       40.046579   \n",
       "7           Full Path (Char) + RandomForest      150.761759   \n",
       "18                Full Path (Hash) + LogReg        1.230849   \n",
       "4           Full Path (Word) + DecisionTree        7.515523   \n",
       "8              Full Path (Char) + KNN (k=3)        0.028875   \n",
       "5             Full Path (Word) + NaiveBayes        0.020721   \n",
       "19          Full Path (Hash) + RandomForest      308.501812   \n",
       "10          Full Path (Char) + DecisionTree       47.994331   \n",
       "11            Full Path (Char) + NaiveBayes        0.041426   \n",
       "9              Full Path (Char) + KNN (k=1)        0.033765   \n",
       "22          Full Path (Hash) + DecisionTree      419.467187   \n",
       "20             Full Path (Hash) + KNN (k=3)        0.098532   \n",
       "2              Full Path (Word) + KNN (k=3)        0.007982   \n",
       "21             Full Path (Hash) + KNN (k=1)        0.053817   \n",
       "3              Full Path (Word) + KNN (k=1)        0.008967   \n",
       "23            Full Path (Hash) + NaiveBayes        0.071264   \n",
       "25          Path Only (Char) + RandomForest      895.194725   \n",
       "30                Path Only (Word) + LogReg        0.118259   \n",
       "31          Path Only (Word) + RandomForest       59.314191   \n",
       "35            Path Only (Word) + NaiveBayes        0.011994   \n",
       "13  Full Path (Custom Token) + RandomForest       21.956469   \n",
       "24                Path Only (Char) + LogReg        0.252705   \n",
       "12        Full Path (Custom Token) + LogReg        0.175038   \n",
       "17    Full Path (Custom Token) + NaiveBayes        0.016001   \n",
       "37           Manual Features + RandomForest        9.585214   \n",
       "16  Full Path (Custom Token) + DecisionTree        1.281159   \n",
       "34          Path Only (Word) + DecisionTree        4.476643   \n",
       "29            Path Only (Char) + NaiveBayes        0.031398   \n",
       "38              Manual Features + KNN (k=3)        0.022209   \n",
       "36                 Manual Features + LogReg        0.968650   \n",
       "28          Path Only (Char) + DecisionTree      597.837565   \n",
       "40           Manual Features + DecisionTree        0.770453   \n",
       "41           Manual Features + DecisionTree        0.770453   \n",
       "39              Manual Features + KNN (k=1)        0.045878   \n",
       "27             Path Only (Char) + KNN (k=1)        0.043965   \n",
       "26             Path Only (Char) + KNN (k=3)        0.094505   \n",
       "32             Path Only (Word) + KNN (k=3)        0.007093   \n",
       "15     Full Path (Custom Token) + KNN (k=1)        0.008979   \n",
       "33             Path Only (Word) + KNN (k=1)        0.010635   \n",
       "14     Full Path (Custom Token) + KNN (k=3)        0.005872   \n",
       "\n",
       "    Inference Time (s)  Accuracy  F1 (Class 0)  Precision (Class 0)  \\\n",
       "6             0.004522  0.919176      0.932156             0.949055   \n",
       "0             0.000756  0.917673      0.930457             0.953595   \n",
       "1             0.334814  0.914488      0.927357             0.956105   \n",
       "7             0.357640  0.913767      0.926202             0.962484   \n",
       "18            0.059881  0.900367      0.916650             0.930021   \n",
       "4             0.007131  0.891833      0.910215             0.916156   \n",
       "8           116.119892  0.891773      0.910429             0.913655   \n",
       "5             0.002521  0.890031      0.910373             0.899797   \n",
       "19            0.665472  0.889189      0.906661             0.926451   \n",
       "10            0.015811  0.888769      0.907704             0.913305   \n",
       "11            0.005857  0.883300      0.902048             0.918353   \n",
       "9           111.089114  0.881197      0.901959             0.902541   \n",
       "22            0.024050  0.858542      0.883269             0.883795   \n",
       "20          209.884235  0.851511      0.870146             0.926063   \n",
       "2            34.716234  0.845803      0.874634             0.862414   \n",
       "21          209.112356  0.843699      0.865268             0.906250   \n",
       "3            30.688173  0.838291      0.867536             0.861725   \n",
       "23            0.011933  0.828015      0.867353             0.814573   \n",
       "25            2.131135  0.802416      0.843458             0.811544   \n",
       "30            0.001301  0.790758      0.831787             0.811328   \n",
       "31            1.295936  0.789616      0.827034             0.824468   \n",
       "35            0.000725  0.780302      0.822714             0.805374   \n",
       "13            0.224109  0.777898      0.830924             0.771557   \n",
       "24            0.011011  0.776997      0.820299             0.801931   \n",
       "12            0.001436  0.773211      0.825002             0.775115   \n",
       "17            0.000798  0.772730      0.826386             0.769645   \n",
       "37            0.308872  0.772129      0.816119             0.798918   \n",
       "16            0.002567  0.767742      0.824294             0.761337   \n",
       "34            0.013065  0.758488      0.804056             0.791211   \n",
       "29            0.003399  0.744487      0.793171             0.778775   \n",
       "38            1.901771  0.731567      0.777085             0.782513   \n",
       "36            0.016606  0.730425      0.797160             0.732934   \n",
       "28            0.008841  0.724956      0.773741             0.771795   \n",
       "40            0.010968  0.722132      0.771202             0.769983   \n",
       "41            0.010968  0.722132      0.771202             0.769983   \n",
       "39            1.765950  0.708611      0.756930             0.765720   \n",
       "27         1446.119750  0.705426      0.783538             0.706538   \n",
       "26         1220.690966  0.691605      0.780721             0.686143   \n",
       "32           19.228129  0.676101      0.721476             0.753644   \n",
       "15           26.331409  0.670152      0.712181             0.756068   \n",
       "33           15.673093  0.669972      0.715086             0.750190   \n",
       "14           30.086631  0.650382      0.702860             0.725003   \n",
       "\n",
       "    Recall (Class 0)  F1 (Class 1)  Precision (Class 1)  Recall (Class 1)  \\\n",
       "6           0.915849      0.900052             0.877046          0.924298   \n",
       "0           0.908415      0.899131             0.868563          0.931929   \n",
       "1           0.900287      0.896078             0.859123          0.936355   \n",
       "7           0.892556      0.896293             0.851201          0.946429   \n",
       "18          0.903657      0.876176             0.857853          0.895299   \n",
       "4           0.904351      0.863987             0.855582          0.872558   \n",
       "8           0.907226      0.863302             0.858674          0.867979   \n",
       "5           0.921201      0.857743             0.874049          0.842033   \n",
       "19          0.887699      0.863670             0.837539          0.891484   \n",
       "10          0.902171      0.860059             0.852135          0.868132   \n",
       "11          0.886312      0.855678             0.833864          0.878663   \n",
       "9           0.901378      0.849280             0.848439          0.850122   \n",
       "22          0.882744      0.820525             0.819775          0.821276   \n",
       "20          0.820597      0.826633             0.764966          0.899115   \n",
       "2           0.887204      0.799750             0.818269          0.782051   \n",
       "21          0.827832      0.813909             0.766061          0.868132   \n",
       "3           0.873427      0.792473             0.800935          0.784188   \n",
       "23          0.927446      0.755510             0.857974          0.674908   \n",
       "25          0.877986      0.732204             0.785016          0.686050   \n",
       "30          0.853306      0.723255             0.754561          0.694444   \n",
       "31          0.829616      0.731539             0.735090          0.728022   \n",
       "35          0.840817      0.711216             0.737066          0.687118   \n",
       "13          0.900188      0.676414             0.793224          0.589591   \n",
       "24          0.839528      0.706199             0.733673          0.680708   \n",
       "12          0.881752      0.677876             0.768978          0.606074   \n",
       "17          0.892160      0.671073             0.780024          0.588828   \n",
       "37          0.834077      0.700474             0.725933          0.676740   \n",
       "16          0.898602      0.657510             0.783858          0.566239   \n",
       "34          0.817326      0.685303             0.703650          0.667888   \n",
       "29          0.808108      0.665828             0.686325          0.646520   \n",
       "38          0.771732      0.662690             0.655806          0.669719   \n",
       "36          0.873724      0.598245             0.723884          0.509768   \n",
       "28          0.775696      0.649353             0.651900          0.646825   \n",
       "40          0.772425      0.646267             0.647853          0.644689   \n",
       "41          0.772425      0.646267             0.647853          0.644689   \n",
       "39          0.748340      0.636316             0.625571          0.647436   \n",
       "27          0.879374      0.539112             0.702008          0.437576   \n",
       "26          0.905541      0.480462             0.713470          0.362179   \n",
       "32          0.691942      0.613065             0.578748          0.651709   \n",
       "15          0.673109      0.613750             0.569395          0.665598   \n",
       "33          0.683120      0.607882             0.571103          0.649725   \n",
       "14          0.682030      0.575390             0.551329          0.601648   \n",
       "\n",
       "    F2 (Class 0)  F2 (Class 1)  F1 (Weighted)  F2 (Weighted)  \n",
       "6       0.922303      0.914444       0.919516       0.919209  \n",
       "0       0.917105      0.918527       0.918123       0.917665  \n",
       "1       0.910923      0.919818       0.915042       0.914425  \n",
       "7       0.905717      0.925716       0.914426       0.913591  \n",
       "18      0.908810      0.887551       0.900714       0.900440  \n",
       "4       0.906688      0.869109       0.892014       0.891892  \n",
       "8       0.908504      0.866102       0.891874       0.891810  \n",
       "5       0.916839      0.848247       0.889651       0.889833  \n",
       "19      0.895188      0.880146       0.889734       0.889266  \n",
       "10      0.904376      0.864885       0.888945       0.888827  \n",
       "11      0.892540      0.869322       0.883791       0.883399  \n",
       "9       0.901610      0.849785       0.881218       0.881205  \n",
       "22      0.882954      0.820975       0.858565       0.858551  \n",
       "20      0.839723      0.868648       0.853014       0.851112  \n",
       "2       0.882133      0.789036       0.845150       0.845478  \n",
       "21      0.842411      0.845598       0.845046       0.843666  \n",
       "3       0.871061      0.787481       0.837982       0.838153  \n",
       "23      0.902436      0.704993       0.823317       0.824698  \n",
       "25      0.863841      0.703795       0.799655       0.800827  \n",
       "30      0.844566      0.705689       0.789056       0.789886  \n",
       "31      0.828582      0.729425       0.789435       0.789541  \n",
       "35      0.833481      0.696559       0.778814       0.779571  \n",
       "13      0.871142      0.621501       0.770089       0.772851  \n",
       "24      0.831729      0.690680       0.775375       0.776195  \n",
       "12      0.858141      0.632889       0.767075       0.769453  \n",
       "17      0.864633      0.619182       0.765235       0.767992  \n",
       "37      0.826800      0.686038       0.770586       0.771378  \n",
       "16      0.867327      0.599528       0.758627       0.761888  \n",
       "34      0.811966      0.674746       0.757300       0.757939  \n",
       "29      0.802066      0.654107       0.743033       0.743811  \n",
       "38      0.773864      0.666890       0.732044       0.731745  \n",
       "36      0.841399      0.541821       0.718842       0.723447  \n",
       "28      0.774913      0.647834       0.724766       0.724879  \n",
       "40      0.771936      0.645319       0.722012       0.722083  \n",
       "41      0.771936      0.645319       0.722012       0.722083  \n",
       "39      0.751752      0.642942       0.709441       0.708911  \n",
       "27      0.838357      0.473227       0.687301       0.694596  \n",
       "26      0.851111      0.401740       0.662501       0.674182  \n",
       "32      0.703460      0.635682       0.678792       0.676774  \n",
       "15      0.688212      0.643842       0.673426       0.670742  \n",
       "33      0.695557      0.632315       0.672877       0.670657  \n",
       "14      0.690212      0.590863       0.652672       0.651096  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results\n",
    "results = pd.DataFrame(results).sort_values('Accuracy', ascending=False)\n",
    "#print(\"\\nSummary:\\n\", results)\n",
    "\n",
    "results.sort_values('Accuracy',ascending=False,inplace=True)\n",
    "#results.sort_values('F1 (Weighted)',ascending=False)\n",
    "#results.sort_values('F2 (Weighted)',ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "755a850a-0329-4038-bba0-c2c791754a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "Strategy & Train Time (s) & Inference Time (s) & Accuracy & F1 (Weighted) & F2 (Weighted) \\\\\n",
      "\\midrule\n",
      "Full Path (Char) + LogReg & 78.3\\% & 0.5\\% & 91.9\\% & 92.0\\% & 91.9\\% \\\\\n",
      "Full Path (Word) + LogReg & 27.4\\% & 0.1\\% & 91.8\\% & 91.8\\% & 91.8\\% \\\\\n",
      "Full Path (Word) + RandomForest & 4004.7\\% & 33.5\\% & 91.4\\% & 91.5\\% & 91.4\\% \\\\\n",
      "Full Path (Char) + RandomForest & 15076.2\\% & 35.8\\% & 91.4\\% & 91.4\\% & 91.4\\% \\\\\n",
      "Full Path (Hash) + LogReg & 123.1\\% & 6.0\\% & 90.0\\% & 90.1\\% & 90.0\\% \\\\\n",
      "Full Path (Word) + DecisionTree & 751.6\\% & 0.7\\% & 89.2\\% & 89.2\\% & 89.2\\% \\\\\n",
      "Full Path (Char) + KNN (k=3) & 2.9\\% & 11612.0\\% & 89.2\\% & 89.2\\% & 89.2\\% \\\\\n",
      "Full Path (Word) + NaiveBayes & 2.1\\% & 0.3\\% & 89.0\\% & 89.0\\% & 89.0\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# latex table with formatting\n",
    "def percentage_format(x):\n",
    "    return f\"{x*100:.1f}\\\\%\"\n",
    "\n",
    "latex_table = results.head(8)[['Strategy', 'Train Time (s)', 'Inference Time (s)', 'Accuracy', 'F1 (Weighted)', 'F2 (Weighted)']].to_latex(\n",
    "    index=False,\n",
    "    float_format=percentage_format\n",
    ")\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c96a2d0-44e4-49cd-ac9a-e3de0a629bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Full Path (Word)\n",
      "Saving Full Path (Char)\n",
      "Saving Full Path (Custom Token)\n",
      "Saving Full Path (Hash)\n",
      "Saving Path Only (Char)\n",
      "Saving Path Only (Word)\n",
      "Saving Manual Features\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for vectorizers\n",
    "os.makedirs('saved_vectorizers', exist_ok=True)\n",
    "\n",
    "# Save each vectorizer\n",
    "for name, vectorizer in vecs.items():\n",
    "    print(f\"Saving {name}\")\n",
    "    if \"Custom\" not in name:\n",
    "        vectorizer_filename = f\"saved_vectorizers/{name}.joblib\"\n",
    "        joblib.dump(vectorizer, vectorizer_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f0f7338-c224-4288-82f6-93f6c9a7487e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>is_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11052</th>\n",
       "      <td>https://www.governing.com/topics/health-human-...</td>\n",
       "      <td>governing.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70550</th>\n",
       "      <td>https://www.sundancetimes.com/story/2019/04/04...</td>\n",
       "      <td>sundancetimes.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>http://seniorcenter.ellington-ct.gov/Jobs.aspx</td>\n",
       "      <td>ellington-ct.gov</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60128</th>\n",
       "      <td>http://www.fox26houston.com/news/bill-would-pr...</td>\n",
       "      <td>fox26houston.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27140</th>\n",
       "      <td>http://www.thecatholicconnection.org/?p=2081</td>\n",
       "      <td>thecatholicconnection.org</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "11052  https://www.governing.com/topics/health-human-...   \n",
       "70550  https://www.sundancetimes.com/story/2019/04/04...   \n",
       "8349      http://seniorcenter.ellington-ct.gov/Jobs.aspx   \n",
       "60128  http://www.fox26houston.com/news/bill-would-pr...   \n",
       "27140       http://www.thecatholicconnection.org/?p=2081   \n",
       "\n",
       "                          domain  is_news  \n",
       "11052              governing.com      1.0  \n",
       "70550          sundancetimes.com      1.0  \n",
       "8349            ellington-ct.gov      0.0  \n",
       "60128           fox26houston.com      1.0  \n",
       "27140  thecatholicconnection.org      1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dd69519-4624-411a-8028-9ee75f12c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f'saved_models/results_summary_{N_FEATURES}_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7956e3a7-d04c-4564-b68c-2627c3e3e813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fd842-7744-49e6-b8ae-f8f0a2f1dba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
