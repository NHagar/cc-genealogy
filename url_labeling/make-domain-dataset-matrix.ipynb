{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753c70ed-25d8-44b9-9acf-dc4f6e8f4e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1323.54s\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import tldextract\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "df = pd.read_parquet(\"hf://datasets/jackbandy/CC_aggregate/all_domains.parquet\")\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Took {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d86fd-240d-4ea3-b6f5-37d317b9d640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading zyda_main...\n",
      "Loading zyda_fwe3...\n",
      "Loading zyda_dclm_crossdeduped...\n",
      "Loading dclm_baseline_batch4...\n",
      "Loading dclm_dedup...\n",
      "Loading falcon_refinedweb...\n",
      "Loading falcon_main...\n",
      "Loading c4_en...\n",
      "Loading cultura...\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"zyda_main\": \"hf://datasets/nhagar/zyda_urls/**/*.parquet\",\n",
    "    \"zyda_fwe3\": \"hf://datasets/nhagar/zyda-2_urls_fwe3/**/*.parquet\",\n",
    "    \"zyda_dclm_crossdeduped\": \"hf://datasets/nhagar/zyda-2_urls_dclm_crossdeduped/**/*.parquet\",\n",
    "    \"dclm_baseline_batch4\": \"hf://datasets/nhagar/dclm-baseline-1.0-parquet_urls/batch_4/train-*.parquet\",\n",
    "    \"dclm_dedup\": \"hf://datasets/nhagar/dclm-dedup_urls/**/*.parquet\",\n",
    "    \"falcon_refinedweb\": \"hf://datasets/nhagar/falcon-refinedweb_urls/batch*/train-*.parquet\",\n",
    "    \"falcon_main\": \"hf://datasets/nhagar/falcon_urls/data/train-*.parquet\",\n",
    "    \"c4_en\": \"hf://datasets/nhagar/c4_en_urls/data/train-*.parquet\",\n",
    "    \"cultura\": \"hf://datasets/nhagar/cultura_urls/data/train-*.parquet\"\n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "for name, path in datasets.items():\n",
    "    print(f\"Loading {name}...\")\n",
    "    dataframes[name] = dd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb37245-6d00-4376-b755-0d18a711819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def create_domain_matrix(host_df, dataframes, sample=True, sample_frac=0.01):\n",
    "    print(f\"Processing {len(dataframes)} datasets for {len(host_df['url_host_name'].unique())} unique domains\")\n",
    "    all_domains = host_df['url_host_name'].unique()\n",
    "    matrix = np.zeros((len(all_domains), len(dataframes)), dtype=np.int8)\n",
    "    \n",
    "    for col_idx, (dataset_name, df) in enumerate(tqdm(dataframes.items(), desc=\"Datasets\")):\n",
    "        start_time = time.time()        \n",
    "        if 'url' not in df.columns:\n",
    "            print(f\"  WARNING: No URL column in {dataset_name}, skipping\")\n",
    "            continue\n",
    "            \n",
    "        url_sample = (df['url'].sample(frac=sample_frac) if sample else df['url']).compute()\n",
    "        print(f\"  {'Sample' if sample else 'Full dataset'}: {len(url_sample)} URLs from {dataset_name}\")\n",
    "        \n",
    "        domains_set = set()\n",
    "        for url in tqdm(url_sample, desc=\"  Extracting domains\", unit=\"URL\"):\n",
    "            if pd.notna(url) and '//' in url:\n",
    "                host = url.split('//')[1].split('/')[0]\n",
    "                domains_set.add(host)\n",
    "        \n",
    "        domains_found = 0\n",
    "        for row_idx, domain in enumerate(tqdm(all_domains, desc=\"  Matching domains\")):\n",
    "            if domain in domains_set:\n",
    "                matrix[row_idx, col_idx] = 1\n",
    "                domains_found += 1\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"  âœ“ {dataset_name}: Found {domains_found} domains in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return pd.DataFrame(matrix, index=all_domains, columns=list(dataframes.keys()))\n",
    "\n",
    "# Usage\n",
    "print(\"Starting domain matrix creation...\")\n",
    "start_time = time.time()\n",
    "domain_matrix = create_domain_matrix(host_df=df, dataframes=dataframes, sample=True, sample_frac=0.01)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Domain matrix creation finished in {total_time:.2f} seconds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cdc8d2-d0e4-4acb-875f-a98d699ab2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
